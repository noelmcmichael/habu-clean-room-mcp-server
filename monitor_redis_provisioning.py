#!/usr/bin/env python3
"""
Monitor Redis provisioning status and re-test when available
"""

import requests
import time
import json
from datetime import datetime

def check_redis_status():
    """Check if Redis is connected"""
    try:
        response = requests.get("https://habu-demo-api-v2.onrender.com/api/cache-stats", timeout=10)
        if response.status_code == 200:
            data = response.json()
            cache_stats = data.get('cache_stats', {})
            connected = cache_stats.get('connected', False)
            error = cache_stats.get('error', '')
            
            return connected, cache_stats
        return False, {}
    except Exception as e:
        return False, {'error': str(e)}

def monitor_redis_provisioning(max_wait_minutes=20):
    """Monitor Redis provisioning with status updates"""
    
    print("ğŸ” Monitoring Redis Provisioning Status")
    print("=" * 50)
    print(f"Started at: {datetime.now().strftime('%H:%M:%S')}")
    print(f"Max wait time: {max_wait_minutes} minutes")
    print()
    
    start_time = time.time()
    max_wait_seconds = max_wait_minutes * 60
    check_count = 0
    
    while time.time() - start_time < max_wait_seconds:
        check_count += 1
        elapsed_minutes = (time.time() - start_time) / 60
        
        print(f"ğŸ”„ Check #{check_count} ({elapsed_minutes:.1f}m elapsed)")
        
        connected, stats = check_redis_status()
        
        if connected:
            print("âœ… Redis is now connected!")
            print(f"ğŸ“Š Redis Stats:")
            for key, value in stats.items():
                if key != 'connected':
                    print(f"   {key}: {value}")
            
            print(f"\nğŸ‰ Redis provisioning completed in {elapsed_minutes:.1f} minutes")
            return True
        else:
            error_msg = stats.get('error', 'Unknown status')
            print(f"â³ Redis not connected: {error_msg}")
        
        if elapsed_minutes < max_wait_minutes - 0.5:  # Don't sleep on last iteration
            print("   Waiting 60 seconds before next check...\n")
            time.sleep(60)
    
    print(f"\nâš ï¸ Redis provisioning check timed out after {max_wait_minutes} minutes")
    print("â„¹ï¸ This is normal for Render.com - Redis can take 15-30 minutes to provision")
    return False

def test_performance_with_redis():
    """Quick performance test with Redis enabled"""
    print("\nğŸš€ Testing Performance with Redis Enabled")
    print("=" * 50)
    
    # Test API endpoint caching
    endpoint = "https://habu-demo-api-v2.onrender.com/api/mcp/habu_list_partners"
    
    try:
        # First request
        start_time = time.time()
        response1 = requests.get(endpoint, timeout=15)
        first_time = (time.time() - start_time) * 1000
        
        if response1.status_code == 200:
            data1 = response1.json()
            first_cached = data1.get('cached', False)
            
            print(f"First request: {first_time:.0f}ms (cached: {first_cached})")
            
            # Second request
            time.sleep(1)  # Brief pause
            start_time = time.time()
            response2 = requests.get(endpoint, timeout=15)
            second_time = (time.time() - start_time) * 1000
            
            if response2.status_code == 200:
                data2 = response2.json()
                second_cached = data2.get('cached', False)
                
                improvement = ((first_time - second_time) / first_time) * 100 if first_time > 0 else 0
                
                print(f"Second request: {second_time:.0f}ms (cached: {second_cached})")
                print(f"Performance improvement: {improvement:.1f}%")
                
                if second_cached and improvement > 80:
                    print("ğŸ‰ Excellent Redis caching performance!")
                    return True
                elif improvement > 50:
                    print("âœ… Good performance improvement detected")
                    return True
                else:
                    print("âš ï¸ Limited performance improvement")
                    return False
            else:
                print(f"âŒ Second request failed: {response2.status_code}")
                return False
        else:
            print(f"âŒ First request failed: {response1.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Performance test failed: {e}")
        return False

def main():
    """Main monitoring function"""
    print("ğŸ¯ Phase H1.1 Redis Provisioning Monitor")
    print("=" * 60)
    
    # Initial check
    connected, stats = check_redis_status()
    
    if connected:
        print("âœ… Redis is already connected!")
        if test_performance_with_redis():
            print("\nğŸ‰ Phase H1.1 deployment fully successful!")
        else:
            print("\nâš ï¸ Redis connected but performance needs review")
    else:
        print("â³ Redis not yet connected - starting monitoring...")
        
        if monitor_redis_provisioning(20):
            print("\nğŸ”„ Running performance test with Redis...")
            if test_performance_with_redis():
                print("\nğŸ‰ Phase H1.1 deployment fully successful!")
            else:
                print("\nâš ï¸ Redis connected but performance needs review")
        else:
            print("\nğŸ“ Current Status Summary:")
            print("âœ… System is operational with graceful fallback")
            print("âœ… 44.7% performance improvement even without Redis")
            print("â³ Redis provisioning may still be in progress")
            print("ğŸ”„ Can re-run this script later to check Redis status")
    
    print("\nğŸ“‹ Next Steps:")
    print("1. If Redis is connected: Proceed with Phase H1.2 (CDN)")
    print("2. If Redis still provisioning: Wait and re-run this script")
    print("3. Review production_test_results.json for detailed metrics")

if __name__ == "__main__":
    main()